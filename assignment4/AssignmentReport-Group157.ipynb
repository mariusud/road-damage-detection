{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1ab)\n",
    "\n",
    "![](/home/marius/Development/Datasyn/assignment4/prob1.jpg)\n",
    "## task 1c)\n",
    "\n",
    "mAP = (0.73 + 0.675) / 2 = 0.7025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "\n",
    "![](/home/marius/Development/Datasyn/assignment4/task2/precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "The SSD architecture produces a fixed-size number of bounding boxes and a score for eachbounding box.  When performing inference with SSD, we need to filter out a set of overlappingboxes.  What is this filtering operation called?\n",
    "non-maximum suppression (NMS) \n",
    "\n",
    "### Task 3b)\n",
    "The SSD architecture predicts bounding boxes at multiple scales to enable the network todetect objects of different sizes.Is the following true or false:Predictions from the deeper layers in SSD are responsible todetect small objects\n",
    "\n",
    "Higher-resolution feature maps are responsible for detecting small objects. since the resolution decreases for each layer, predictions from the deeper layers are responsible for detecting bigger objects.\n",
    "\n",
    "### Task 3c)\n",
    "SSD use k number of ”anchors” with different aspect ratios at each spatial location in a feature map to predict class scores and 4 offsets relative to the original box shape.Why do they use different bounding box aspect ratios at the same spatial location?\n",
    "\n",
    "Objects can have wildly varying shapes, as cars will often be more rectangular, and e.g. a football will have a squared bounding box. To get a bigger IoU between prediction and gt_box, the SSD will predict a number of objects with varying shapes at the same spatial location. The team behind SSD discovered that the model will fight between the different aspect ratios thus leaving the predictions unstable. To counter this, they start guesses based on \"default\" boxes that are preselected manually and carefully.\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "What is the main difference between SSD and YOLOv1/v2 (The YOLO version they refer to in the SSD paper)?\n",
    "The main difference in the network model is that SSD adds several feature layers at the end of the base network, which predict the offsets to default boxes of different scales and aspect ratios and their associated confidences.\n",
    "The default bounding boxes discussed above are also not entered manually, but found through k-means clustering in the YOLO algorithm\n",
    "\n",
    "### Task 3e)\n",
    "Given a SSD framework, where the first scale the network predicts at is at the last featuremap with a resolution of 38×38 (H×W).  For each anchor location, we place 6 different anchorswith different aspect ratios.  How many anchors boxes do we have in total for this feature map?\n",
    "We get 38 x 38 x 6 =  8664 anchor boxes \n",
    "\n",
    "### Task 3f)\n",
    "The network outlined in the previous subtask predicts at multiple resolutions, specifically38×38, 19×19, 10×10, 5×5, 3×3 and 1×1.  It uses 6 different aspect ratios at each location inevery feature map as anchors.  How many anchors boxes do we have in total for the entire network?\n",
    "total anchors = 6x(38x38 + 19x19 + 10x10 + 5x5 + 3x3 + 1x1) \n",
    "so we get a grand total of 11640 anchor boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "![](/home/marius/Development/Datasyn/assignment4/total_loss_prob3.png)\n",
    "\n",
    "\n",
    "After 6000 iterations the SSD reached a mAP of 75.76%\n",
    "```\n",
    "2021-03-18 13:02:59,766 SSD.trainer INFO: iter: 005990, lr: 0.00200, total_loss: 2.496 (3.524), reg_loss: 0.648 (0.880), cls_loss: 1.849 (2.644), time: 0.090 (0.116), eta: 0:07:43, mem: 1263M\n",
    "2021-03-18 13:03:01,074 SSD.trainer INFO: iter: 006000, lr: 0.00200, total_loss: 2.475 (3.522), reg_loss: 0.625 (0.879), cls_loss: 1.849 (2.643), time: 0.131 (0.116), eta: 0:07:42, mem: 1263M\n",
    "2021-03-18 13:03:01,110 SSD.trainer INFO: Saving checkpoint to outputs/basic/model_006000.pth\n",
    "2021-03-18 13:03:01,788 SSD.inference INFO: Evaluating mnist_detection_val dataset(1000 images):\n",
    "2021-03-18 13:03:06,635 SSD.inference INFO: mAP: 0.7576\n",
    "0               : 0.8055\n",
    "1               : 0.6246\n",
    "2               : 0.7436\n",
    "3               : 0.7788\n",
    "4               : 0.7984\n",
    "5               : 0.7696\n",
    "6               : 0.7826\n",
    "7               : 0.7615\n",
    "8               : 0.7819\n",
    "9               : 0.7291\n",
    "```\n",
    "## Task 4c)\n",
    "From the last assignment we learned that batch normalization had the greatest effect on the accuracy of the data. This was thus implemented after the last convolution of each layer.\n",
    "Furthermore, the Adam optimizer was implemented as we saw this improved training time and accuracy as well from assignment 3. Learning rate was set to 1e-3.\n",
    "ReLU was replaced with LeakyReLU.\n",
    "\n",
    "```\n",
    "2021-03-18 17:09:00,364 SSD.trainer INFO: iter: 008980, lr: 0.00100, total_loss: 1.790 (2.260), reg_loss: 0.486 (0.590), cls_loss: 1.304 (1.670), time: 0.065 (0.076), eta: 0:01:17, mem: 2073M\n",
    "2021-03-18 17:09:01,063 SSD.trainer INFO: iter: 008990, lr: 0.00100, total_loss: 1.770 (2.259), reg_loss: 0.469 (0.590), cls_loss: 1.301 (1.669), time: 0.070 (0.076), eta: 0:01:16, mem: 2073M\n",
    "2021-03-18 17:09:01,730 SSD.trainer INFO: iter: 009000, lr: 0.00100, total_loss: 1.773 (2.259), reg_loss: 0.478 (0.590), cls_loss: 1.295 (1.669), time: 0.067 (0.076), eta: 0:01:16, mem: 2073M\n",
    "2021-03-18 17:09:01,756 SSD.trainer INFO: Saving checkpoint to outputs/improved_basic/model_009000.pth\n",
    "2021-03-18 17:09:02,701 SSD.inference INFO: Evaluating mnist_detection_val dataset(1000 images):\n",
    "2021-03-18 17:09:06,132 SSD.inference INFO: mAP: 0.8524\n",
    "0               : 0.8794\n",
    "1               : 0.7977\n",
    "2               : 0.8367\n",
    "3               : 0.8713\n",
    "4               : 0.8644\n",
    "5               : 0.8541\n",
    "6               : 0.8627\n",
    "7               : 0.8397\n",
    "8               : 0.8778\n",
    "9               : 0.8402\n",
    "```\n",
    "\n",
    "## Task 4d)\n",
    "Doing some analysis we think that one of the issue that needs to be addressed before you can achieve 90% mAP is that the manually coded sizes for the anchors are not specifically scaled or proportioned for this dataset. After looking at some of the images it becomes clear that a lot of the letters are really small and some are really big. the key here is that the size vary wildly from image to image. We therefore increased the size both smaller and bigger in the mnist yaml file. Batch size was increased to 32, max_iter to 15000 and threshold reduced to 0.45\n",
    "```\n",
    "MODEL:\n",
    "    NUM_CLASSES: 11\n",
    "    BACKBONE:\n",
    "        NAME: 'basic'\n",
    "        PRETRAINED: False\n",
    "        OUT_CHANNELS: [128, 256, 128, 128, 64, 64]\n",
    "        INPUT_CHANNELS: 3\n",
    "    PRIORS:\n",
    "        MAX_SIZES: [[38, 38], [90, 90], [153, 153], [207, 207], [264, 264], [312, 312]]\n",
    "        MIN_SIZES: [[16, 16], [38, 38], [90, 90], [153, 153], [207, 207], [264, 264]]\n",
    "    THRESHOLD: 0.45\n",
    "INPUT:\n",
    "    IMAGE_SIZE: [300, 300]\n",
    "DATASETS:\n",
    "    TRAIN: (\"mnist_detection_train\", \"mnist_detection_val\")\n",
    "    TEST: (\"mnist_detection_val\", )\n",
    "SOLVER:\n",
    "    MAX_ITER: 15000\n",
    "    GAMMA: 0.1\n",
    "    BATCH_SIZE: 32\n",
    "    \n",
    "\n",
    "OUTPUT_DIR: 'outputs/improved_basic'\n",
    "DATASET_DIR: \"/work/datasets\"\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Finally a mAP of 90.36% was reached after 4500 iterations. Final mAP after 15k iterations was 90.52%\n",
    "```\n",
    "2021-03-18 20:56:36,594 SSD.trainer INFO: iter: 004470, lr: 0.00100, total_loss: 1.057 (1.633), reg_loss: 0.350 (0.482), cls_loss: 0.707 (1.151), time: 0.133 (0.154), eta: 0:26:58, mem: 3091M\n",
    "2021-03-18 20:56:37,902 SSD.trainer INFO: iter: 004480, lr: 0.00100, total_loss: 1.022 (1.631), reg_loss: 0.335 (0.482), cls_loss: 0.687 (1.150), time: 0.131 (0.154), eta: 0:26:56, mem: 3091M\n",
    "2021-03-18 20:56:39,256 SSD.trainer INFO: iter: 004490, lr: 0.00100, total_loss: 1.056 (1.630), reg_loss: 0.352 (0.482), cls_loss: 0.704 (1.149), time: 0.135 (0.154), eta: 0:26:54, mem: 3091M\n",
    "2021-03-18 20:56:40,599 SSD.trainer INFO: iter: 004500, lr: 0.00100, total_loss: 1.020 (1.629), reg_loss: 0.345 (0.481), cls_loss: 0.675 (1.147), time: 0.134 (0.154), eta: 0:26:52, mem: 3091M\n",
    "2021-03-18 20:56:40,665 SSD.trainer INFO: Saving checkpoint to outputs/improved_basic/model_004500.pth\n",
    "2021-03-18 20:56:40,910 SSD.inference INFO: Evaluating mnist_detection_val dataset(1000 images):\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 37.51it/s]\n",
    "2021-03-18 20:56:44,424 SSD.inference INFO: mAP: 0.9036\n",
    "0               : 0.9081\n",
    "1               : 0.8777\n",
    "2               : 0.9074\n",
    "3               : 0.9082\n",
    "4               : 0.9065\n",
    "5               : 0.9075\n",
    "6               : 0.9069\n",
    "7               : 0.9007\n",
    "8               : 0.9081\n",
    "9               : 0.9048\n",
    "```\n",
    "## Task 4e)\n",
    "Most digits are actually recognized, but there is some internal battle on some of the digits i.e. the SSD is not sure what the number is.\n",
    "Really small numbers are also not always recognized.\n",
    "\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/0.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/1.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/2.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/3.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/4.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/5.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/6.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/7.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/8.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/9.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/10.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/11.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/12.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/13.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/mnist/result/14.png)\n",
    "\n",
    "\n",
    "## Task 4f)\n",
    "\n",
    "```\n",
    "2021-03-19 18:19:49,626 SSD.inference INFO: mAP: 0.1372\n",
    "aeroplane       : 0.2276\n",
    "bicycle         : 0.1524\n",
    "bird            : 0.0579\n",
    "boat            : 0.0913\n",
    "bottle          : 0.0000\n",
    "bus             : 0.1490\n",
    "car             : 0.3093\n",
    "cat             : 0.2334\n",
    "chair           : 0.0219\n",
    "cow             : 0.0830\n",
    "diningtable     : 0.1284\n",
    "dog             : 0.1782\n",
    "horse           : 0.2548\n",
    "motorbike       : 0.2046\n",
    "person          : 0.2868\n",
    "pottedplant     : 0.0003\n",
    "sheep           : 0.1011\n",
    "sofa            : 0.0393\n",
    "train           : 0.1271\n",
    "tvmonitor       : 0.0974\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/notebooks/4f.png)\n",
    "\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/voc/result/000342.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/voc/result/000542.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/voc/result/003123.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/voc/result/008591.png)\n",
    "![](/home/marius/Development/Datasyn/assignment4/SSD/demo/voc/result/004101.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}